{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml19_dnn_cnn_ex.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNANrVIbfHUC4NKHVsJs7Yw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JakeOh/202011_itw_bd21/blob/main/lab_ml/ml19_dnn_cnn_ex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZCFufOAfcfs"
      },
      "source": [
        "# CIFAR10 Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xkk90-LfsfM"
      },
      "source": [
        "0. cifar10 이미지 데이터셋을 다운로드하고, 훈련/검증/테스트 셋으로 분리하세요.\n",
        "cifar10 데이터셋은 32x32 크기의 컬러 이미지 60,000개와 10개의 클래스로 이루어져 있습니다.\n",
        "\n",
        "1. 100개의 뉴런을 가진 은닉층 20개로 DNN(심층 신경망)을 만드세요.\n",
        "ELU 활성화 함수(activation)와 He 커널 초기화(kernel_initializer)를 사용하세요.\n",
        "\n",
        "2. Nadam optimizer와 조기 종료(EarlyStopping)을 사용하여 cifar10 데이터 셋으로 신경망을 훈련하세요.\n",
        "optimizer의 학습률은 5e-5으로 설정하세요.\n",
        "\n",
        "3. 배치 정규화(BatchNormalization)을 추가하고 위 모델과 비교하세요. \n",
        "\n",
        "> Hint\n",
        "```\n",
        "model.add(keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Activation(\"elu\"))\n",
        "```\n",
        "\n",
        "4. 100개의 뉴런을 가진 은닉층 20개로 DNN(심층 신경망)을 만드세요. SELU 활성화 함수(activation)와 르쿤 정규분포(lecun_normal) 커널 초기화(kernel_initializer)를 사용하세요.\n",
        "입력 특성들(훈련 셋, 검증 셋, 테스트 셋)은 정규화(StandardScaler)를 사용하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0f6-5HSsOdE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZKSKryCgGcz"
      },
      "source": [
        "# MNIST 데이터셋 CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-z51IRMsTTT"
      },
      "source": [
        "아래와 같은 구조로 CNN(합성곱 신경망)을 만드세요.\n",
        "\n",
        "*   Convolution: 64개 필터, 7x7 크기 커널, ReLU 활성화, same padding\n",
        "*   Max Pooling: 2x2 필터\n",
        "*   Convolution: 128개 필터, 3x3 크기 커널, ReLU 활성화, same padding\n",
        "*   Convolution: 128개 필터, 3x3 크기 커널, ReLU 활성화, same padding\n",
        "*   Max Pooling: 2x2 필터\n",
        "*   Convolution: 256개 필터, 3x3 크기 커널, ReLU 활성화, same padding\n",
        "*   Convolution: 256개 필터, 3x3 크기 커널, ReLU 활성화, same padding\n",
        "*   Max Pooling: 2x2 필터\n",
        "*   Flatten\n",
        "*   완전연결(Dense)층: 128개 뉴런, ReLU 활성화\n",
        "*   Dropout: 50%\n",
        "*   완전연결(Dense)층: 64개 뉴런, ReLU 활성화\n",
        "*   Dropout: 50%\n",
        "*   출력층\n",
        "\n",
        "Nadam 옵티마이저와 조기종료 콜백을 사용해서 모델을 훈련하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYF9ubyYfS-S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}